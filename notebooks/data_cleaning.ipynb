{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing Notebook\n",
    "\n",
    "This notebook is designed to clean and preprocess data from various sources, including news articles, fake news datasets, and stock market data. The workflow includes loading raw data, cleaning it, extracting relevant information, and saving the processed data for further analysis. \n",
    "\n",
    "### Key Sections:\n",
    "1. **News Data**: \n",
    "    - Extract and clean data from sources like Alpha Vantage, Markets Insider, and Google Search.\n",
    "    - Merge and deduplicate news data for multiple stock symbols.\n",
    "\n",
    "2. **Fake News Data**:\n",
    "    - Process training and testing datasets for fake news detection.\n",
    "    - Remove duplicates and save cleaned datasets.\n",
    "\n",
    "3. **Stock Data**:\n",
    "    - Clean and preprocess stock market data from Alpha Vantage.\n",
    "    - Standardize column names and formats.\n",
    "\n",
    "This notebook ensures that the data is ready for downstream tasks such as analysis, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Enable auto-reload for modules during development\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set display options for Pandas to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Custom libraries\n",
    "from nlp_scripts import data_cleaning as cl\n",
    "from nlp_scripts import data_check as ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folder path\n",
    "data_folder = '../data/data_to_clean/'\n",
    "\n",
    "# Data folder path cleaned data\n",
    "data_folder_cleaned = '../data/data_cleaned'\n",
    "\n",
    "# Load news dataframes\n",
    "news_dict = cl.load_news_dataframes(data_folder)\n",
    "\n",
    "# Load stocks dataframes from Alpha Vantage\n",
    "stocks_dict = cl.load_stocks_dataframes(data_folder, 'stocks', 'alpha_vantage.csv')\n",
    "# Load stocks dataframes from Yahoo Finance\n",
    "stocks_dict_yahoo = cl.load_stocks_dataframes(data_folder, 'stock', 'yahoo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AAPL_alpha_vantage', 'AAPL_markets_insider', 'AMZN_google_search', 'AMZN_alpha_vantage', 'AMZN_markets_insider', 'AAPL_google_search', 'BAC_alpha_vantage', 'BAC_markets_insider', 'BAC_google_search', 'GME_google_search', 'GME_alpha_vantage', 'GME_markets_insider', 'GS_google_search', 'GS_alpha_vantage', 'GS_markets_insider', 'NVDA_alpha_vantage', 'NVDA_markets_insider', 'NVDA_google_search', 'TSLA_google_search', 'TSLA_alpha_vantage', 'TSLA_markets_insider'])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The keys that define the different data frames in news_dict\n",
    "news_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AAPL_alpha_vantage', 'AMZN_alpha_vantage', 'BAC_alpha_vantage', 'GME_alpha_vantage', 'GS_alpha_vantage', 'NVDA_alpha_vantage', 'TSLA_alpha_vantage'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The keys that define the different data frames in stocks_dict\n",
    "stocks_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['stock_AAPL_yahoo', 'stock_AMZN_yahoo', 'stock_BAC_yahoo', 'stock_GME_yahoo', 'stock_GS_yahoo', 'stock_NVDA_yahoo', 'stock_TSLA_yahoo'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The keys that define the different data frames in stocks_dict_yahoo\n",
    "stocks_dict_yahoo.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "time_published",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "banner_image",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category_within_source",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "source_domain",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "topics",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "overall_sentiment_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "overall_sentiment_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ticker_sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8e0c9ee4-aad6-4fb0-8f3e-06669d69c81b",
       "rows": [
        [
         "0",
         "Trump's Tariffs Stir Global Markets, Wall Street Loses $2 Trillion, And More: This Week In Economics - Apple  ( NASDAQ:AAPL ) ",
         "https://www.benzinga.com/media/25/04/44657800/trumps-tariffs-stir-global-markets-wall-street-loses-2-trillion-and-more-this-week-in-economics",
         "2025-04-06 10:00:38",
         "['Ananya Gairola']",
         "The past week was a rollercoaster ride for global markets, largely due to President Donald Trump's new trade tariffs. The tariffs, aimed at reducing America's $1.2 trillion annual trade deficit, have sparked a flurry of reactions from economists, investors, and market observers.",
         "https://cdn.benzinga.com/files/images/story/2025/04/06/Donald-Trump.jpeg?width=1200&height=800&fit=crop",
         "Benzinga",
         "News",
         "www.benzinga.com",
         "[{'topic': 'Economy - Monetary', 'relevance_score': '0.158519'}, {'topic': 'Technology', 'relevance_score': '1.0'}, {'topic': 'Financial Markets', 'relevance_score': '0.108179'}]",
         "0.002465",
         "Neutral",
         "[{'ticker': 'AAPL', 'relevance_score': '0.236972', 'ticker_sentiment_score': '-0.103752', 'ticker_sentiment_label': 'Neutral'}]"
        ],
        [
         "1",
         "3 Top Buffett Stocks to Buy and Hold for the Next 20 Years",
         "https://www.fool.com/investing/2025/04/05/3-top-buffett-stocks-buy-hold-next-20-years/",
         "2025-04-05 22:03:00",
         "['John Ballard', 'and Jennifer Saibil', 'Jeremy Bowman']",
         "Warren Buffett has built a fortune for Berkshire Hathaway shareholders. Buffett's success at buying stocks of great businesses and holding them for the long term has inspired many investors to follow his style.Berkshire held a stock portfolio worth $271 billion at the end of 2024.",
         "https://g.foolcdn.com/editorial/images/813433/warren-buffett.jpg",
         "Motley Fool",
         null,
         "www.fool.com",
         "[{'topic': 'Retail & Wholesale', 'relevance_score': '0.25'}, {'topic': 'Financial Markets', 'relevance_score': '0.999864'}, {'topic': 'Manufacturing', 'relevance_score': '0.25'}, {'topic': 'Earnings', 'relevance_score': '0.891286'}, {'topic': 'Technology', 'relevance_score': '0.25'}, {'topic': 'Finance', 'relevance_score': '0.25'}]",
         "0.394156",
         "Bullish",
         "[{'ticker': 'DMPZF', 'relevance_score': '0.129983', 'ticker_sentiment_score': '0.200408', 'ticker_sentiment_label': 'Somewhat-Bullish'}, {'ticker': 'AAPL', 'relevance_score': '0.337427', 'ticker_sentiment_score': '0.405771', 'ticker_sentiment_label': 'Bullish'}, {'ticker': 'KO', 'relevance_score': '0.08687', 'ticker_sentiment_score': '0.276582', 'ticker_sentiment_label': 'Somewhat-Bullish'}, {'ticker': 'AMZN', 'relevance_score': '0.256538', 'ticker_sentiment_score': '0.28023', 'ticker_sentiment_label': 'Somewhat-Bullish'}, {'ticker': 'BRK-A', 'relevance_score': '0.043499', 'ticker_sentiment_score': '0.370113', 'ticker_sentiment_label': 'Bullish'}, {'ticker': 'DPZ', 'relevance_score': '0.172713', 'ticker_sentiment_score': '0.23662', 'ticker_sentiment_label': 'Somewhat-Bullish'}]"
        ]
       ],
       "shape": {
        "columns": 13,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>time_published</th>\n",
       "      <th>authors</th>\n",
       "      <th>summary</th>\n",
       "      <th>banner_image</th>\n",
       "      <th>source</th>\n",
       "      <th>category_within_source</th>\n",
       "      <th>source_domain</th>\n",
       "      <th>topics</th>\n",
       "      <th>overall_sentiment_score</th>\n",
       "      <th>overall_sentiment_label</th>\n",
       "      <th>ticker_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump's Tariffs Stir Global Markets, Wall Stre...</td>\n",
       "      <td>https://www.benzinga.com/media/25/04/44657800/...</td>\n",
       "      <td>2025-04-06 10:00:38</td>\n",
       "      <td>['Ananya Gairola']</td>\n",
       "      <td>The past week was a rollercoaster ride for glo...</td>\n",
       "      <td>https://cdn.benzinga.com/files/images/story/20...</td>\n",
       "      <td>Benzinga</td>\n",
       "      <td>News</td>\n",
       "      <td>www.benzinga.com</td>\n",
       "      <td>[{'topic': 'Economy - Monetary', 'relevance_sc...</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[{'ticker': 'AAPL', 'relevance_score': '0.2369...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Top Buffett Stocks to Buy and Hold for the N...</td>\n",
       "      <td>https://www.fool.com/investing/2025/04/05/3-to...</td>\n",
       "      <td>2025-04-05 22:03:00</td>\n",
       "      <td>['John Ballard', 'and Jennifer Saibil', 'Jerem...</td>\n",
       "      <td>Warren Buffett has built a fortune for Berkshi...</td>\n",
       "      <td>https://g.foolcdn.com/editorial/images/813433/...</td>\n",
       "      <td>Motley Fool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.fool.com</td>\n",
       "      <td>[{'topic': 'Retail &amp; Wholesale', 'relevance_sc...</td>\n",
       "      <td>0.394156</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>[{'ticker': 'DMPZF', 'relevance_score': '0.129...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Trump's Tariffs Stir Global Markets, Wall Stre...   \n",
       "1  3 Top Buffett Stocks to Buy and Hold for the N...   \n",
       "\n",
       "                                                 url       time_published  \\\n",
       "0  https://www.benzinga.com/media/25/04/44657800/...  2025-04-06 10:00:38   \n",
       "1  https://www.fool.com/investing/2025/04/05/3-to...  2025-04-05 22:03:00   \n",
       "\n",
       "                                             authors  \\\n",
       "0                                 ['Ananya Gairola']   \n",
       "1  ['John Ballard', 'and Jennifer Saibil', 'Jerem...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  The past week was a rollercoaster ride for glo...   \n",
       "1  Warren Buffett has built a fortune for Berkshi...   \n",
       "\n",
       "                                        banner_image       source  \\\n",
       "0  https://cdn.benzinga.com/files/images/story/20...     Benzinga   \n",
       "1  https://g.foolcdn.com/editorial/images/813433/...  Motley Fool   \n",
       "\n",
       "  category_within_source     source_domain  \\\n",
       "0                   News  www.benzinga.com   \n",
       "1                    NaN      www.fool.com   \n",
       "\n",
       "                                              topics  overall_sentiment_score  \\\n",
       "0  [{'topic': 'Economy - Monetary', 'relevance_sc...                 0.002465   \n",
       "1  [{'topic': 'Retail & Wholesale', 'relevance_sc...                 0.394156   \n",
       "\n",
       "  overall_sentiment_label                                   ticker_sentiment  \n",
       "0                 Neutral  [{'ticker': 'AAPL', 'relevance_score': '0.2369...  \n",
       "1                 Bullish  [{'ticker': 'DMPZF', 'relevance_score': '0.129...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the columns for the AAPL_alpha_vantage dataframe\n",
    "news_dict['AAPL_alpha_vantage'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from Alpha Vantage\n",
    "# This function will extract data from Alpha Vantage and return two dataframes:\n",
    "# one with title, date and scores and another with minimal with date and title only.\n",
    "full_data_by_stock, minimal_data_by_stock = cl.extract_alpha_vantage_per_stock(news_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AAPL', 'AMZN', 'BAC', 'GME', 'GS', 'NVDA', 'TSLA'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the dataframes keys\n",
    "full_data_by_stock.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "overall_sentiment_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "overall_sentiment_label",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "ticker_sentiment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6f3eba34-c218-422b-b931-2f9b04f5d187",
       "rows": [
        [
         "0",
         "Trump's Tariffs Stir Global Markets, Wall Street Loses $2 Trillion, And More: This Week In Economics - Apple  ( NASDAQ:AAPL ) ",
         "2025-04-06 10:00:38",
         "The past week was a rollercoaster ride for global markets, largely due to President Donald Trump's new trade tariffs. The tariffs, aimed at reducing America's $1.2 trillion annual trade deficit, have sparked a flurry of reactions from economists, investors, and market observers.",
         "0.002465",
         "Neutral",
         "[{'ticker': 'AAPL', 'relevance_score': '0.236972', 'ticker_sentiment_score': '-0.103752', 'ticker_sentiment_label': 'Neutral'}]",
         "Alpha Vantage"
        ],
        [
         "1",
         "3 Top Buffett Stocks to Buy and Hold for the Next 20 Years",
         "2025-04-05 22:03:00",
         "Warren Buffett has built a fortune for Berkshire Hathaway shareholders. Buffett's success at buying stocks of great businesses and holding them for the long term has inspired many investors to follow his style.Berkshire held a stock portfolio worth $271 billion at the end of 2024.",
         "0.394156",
         "Bullish",
         "[{'ticker': 'DMPZF', 'relevance_score': '0.129983', 'ticker_sentiment_score': '0.200408', 'ticker_sentiment_label': 'Somewhat-Bullish'}, {'ticker': 'AAPL', 'relevance_score': '0.337427', 'ticker_sentiment_score': '0.405771', 'ticker_sentiment_label': 'Bullish'}, {'ticker': 'KO', 'relevance_score': '0.08687', 'ticker_sentiment_score': '0.276582', 'ticker_sentiment_label': 'Somewhat-Bullish'}, {'ticker': 'AMZN', 'relevance_score': '0.256538', 'ticker_sentiment_score': '0.28023', 'ticker_sentiment_label': 'Somewhat-Bullish'}, {'ticker': 'BRK-A', 'relevance_score': '0.043499', 'ticker_sentiment_score': '0.370113', 'ticker_sentiment_label': 'Bullish'}, {'ticker': 'DPZ', 'relevance_score': '0.172713', 'ticker_sentiment_score': '0.23662', 'ticker_sentiment_label': 'Somewhat-Bullish'}]",
         "Alpha Vantage"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>summary</th>\n",
       "      <th>overall_sentiment_score</th>\n",
       "      <th>overall_sentiment_label</th>\n",
       "      <th>ticker_sentiment</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump's Tariffs Stir Global Markets, Wall Stre...</td>\n",
       "      <td>2025-04-06 10:00:38</td>\n",
       "      <td>The past week was a rollercoaster ride for glo...</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[{'ticker': 'AAPL', 'relevance_score': '0.2369...</td>\n",
       "      <td>Alpha Vantage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Top Buffett Stocks to Buy and Hold for the N...</td>\n",
       "      <td>2025-04-05 22:03:00</td>\n",
       "      <td>Warren Buffett has built a fortune for Berkshi...</td>\n",
       "      <td>0.394156</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>[{'ticker': 'DMPZF', 'relevance_score': '0.129...</td>\n",
       "      <td>Alpha Vantage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 date  \\\n",
       "0  Trump's Tariffs Stir Global Markets, Wall Stre...  2025-04-06 10:00:38   \n",
       "1  3 Top Buffett Stocks to Buy and Hold for the N...  2025-04-05 22:03:00   \n",
       "\n",
       "                                             summary  overall_sentiment_score  \\\n",
       "0  The past week was a rollercoaster ride for glo...                 0.002465   \n",
       "1  Warren Buffett has built a fortune for Berkshi...                 0.394156   \n",
       "\n",
       "  overall_sentiment_label                                   ticker_sentiment  \\\n",
       "0                 Neutral  [{'ticker': 'AAPL', 'relevance_score': '0.2369...   \n",
       "1                 Bullish  [{'ticker': 'DMPZF', 'relevance_score': '0.129...   \n",
       "\n",
       "          source  \n",
       "0  Alpha Vantage  \n",
       "1  Alpha Vantage  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL_alpha_vantage dataframe with the sentiment scores\n",
    "full_data_by_stock['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e3e3ab83-c8ae-4942-9948-f9de89a61c05",
       "rows": [
        [
         "0",
         "Trump's Tariffs Stir Global Markets, Wall Street Loses $2 Trillion, And More: This Week In Economics - Apple  ( NASDAQ:AAPL ) ",
         "2025-04-06 10:00:38",
         "Alpha Vantage"
        ],
        [
         "1",
         "3 Top Buffett Stocks to Buy and Hold for the Next 20 Years",
         "2025-04-05 22:03:00",
         "Alpha Vantage"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trump's Tariffs Stir Global Markets, Wall Stre...</td>\n",
       "      <td>2025-04-06 10:00:38</td>\n",
       "      <td>Alpha Vantage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Top Buffett Stocks to Buy and Hold for the N...</td>\n",
       "      <td>2025-04-05 22:03:00</td>\n",
       "      <td>Alpha Vantage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                 date  \\\n",
       "0  Trump's Tariffs Stir Global Markets, Wall Stre...  2025-04-06 10:00:38   \n",
       "1  3 Top Buffett Stocks to Buy and Hold for the N...  2025-04-05 22:03:00   \n",
       "\n",
       "          source  \n",
       "0  Alpha Vantage  \n",
       "1  Alpha Vantage  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL_alpha_vantage dataframe without the sentiment scores\n",
    "minimal_data_by_stock['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL\n",
      "First date: 2025-02-12\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: AMZN\n",
      "First date: 2025-02-06\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: BAC\n",
      "First date: 2025-01-28\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: GME\n",
      "First date: 2024-06-10\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: GS\n",
      "First date: 2025-02-21\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: NVDA\n",
      "First date: 2025-03-20\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: TSLA\n",
      "First date: 2025-03-15\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: AAPL\n",
      "First date: 2025-02-12\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: AMZN\n",
      "First date: 2025-02-06\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: BAC\n",
      "First date: 2025-01-28\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: GME\n",
      "First date: 2024-06-10\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: GS\n",
      "First date: 2025-02-21\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: NVDA\n",
      "First date: 2025-03-20\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n",
      "Stock: TSLA\n",
      "First date: 2025-03-15\n",
      "Last date: 2025-04-06\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set date as index and format columns \n",
    "dataframes_cleaned_alpha_vantage = cl.convert_date(minimal_data_by_stock)\n",
    "dataframes_cleaned_alpha_vantage_with_sentiment = cl.convert_date(full_data_by_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving date column as first column\n",
    "dataframes_cleaned_alpha_vantage = cl.move_date_column_to_front(dataframes_cleaned_alpha_vantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "203ddcb3-ce4e-4e07-ba9c-751fdeac1116",
       "rows": [
        [
         "0",
         "2025-04-06",
         "Trump's Tariffs Stir Global Markets, Wall Street Loses $2 Trillion, And More: This Week In Economics - Apple  ( NASDAQ:AAPL ) ",
         "Alpha Vantage"
        ],
        [
         "1",
         "2025-04-05",
         "3 Top Buffett Stocks to Buy and Hold for the Next 20 Years",
         "Alpha Vantage"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-06</td>\n",
       "      <td>Trump's Tariffs Stir Global Markets, Wall Stre...</td>\n",
       "      <td>Alpha Vantage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-05</td>\n",
       "      <td>3 Top Buffett Stocks to Buy and Hold for the N...</td>\n",
       "      <td>Alpha Vantage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2025-04-06  Trump's Tariffs Stir Global Markets, Wall Stre...   \n",
       "1  2025-04-05  3 Top Buffett Stocks to Buy and Hold for the N...   \n",
       "\n",
       "          source  \n",
       "0  Alpha Vantage  \n",
       "1  Alpha Vantage  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL_alpha_vantage dataframe without the sentiment scores\n",
    "dataframes_cleaned_alpha_vantage['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved news_cleaned_dataframe_AAPL_alpha_vantage.csv\n",
      "Saved news_cleaned_dataframe_AMZN_alpha_vantage.csv\n",
      "Saved news_cleaned_dataframe_BAC_alpha_vantage.csv\n",
      "Saved news_cleaned_dataframe_GME_alpha_vantage.csv\n",
      "Saved news_cleaned_dataframe_GS_alpha_vantage.csv\n",
      "Saved news_cleaned_dataframe_NVDA_alpha_vantage.csv\n",
      "Saved news_cleaned_dataframe_TSLA_alpha_vantage.csv\n",
      "Saved news_cleaned_dataframe_AAPL_alpha_vantage_with_sentiment.csv\n",
      "Saved news_cleaned_dataframe_AMZN_alpha_vantage_with_sentiment.csv\n",
      "Saved news_cleaned_dataframe_BAC_alpha_vantage_with_sentiment.csv\n",
      "Saved news_cleaned_dataframe_GME_alpha_vantage_with_sentiment.csv\n",
      "Saved news_cleaned_dataframe_GS_alpha_vantage_with_sentiment.csv\n",
      "Saved news_cleaned_dataframe_NVDA_alpha_vantage_with_sentiment.csv\n",
      "Saved news_cleaned_dataframe_TSLA_alpha_vantage_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the data frames\n",
    "cl.save_cleaned_dataframes(dataframes_cleaned_alpha_vantage, \"alpha_vantage\", data_folder_cleaned, prefix_word=\"news\")\n",
    "cl.save_cleaned_dataframes(dataframes_cleaned_alpha_vantage_with_sentiment, \"alpha_vantage_with_sentiment\", data_folder_cleaned, prefix_word=\"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markets Insider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "publish_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c89adc70-31a2-4364-b4f8-a5e96f43d77d",
       "rows": [
        [
         "0",
         "4/4/2025 9:14:54 PM",
         "AAPL, JPM, GM: U.S. Stock Market Has Lost 11 Trillion Since Trumps Inauguration",
         "Markets Insider"
        ],
        [
         "1",
         "4/4/2025 5:49:29 PM",
         "Earnings Could Drop by 28, Says Needham about Apple Stock (AAPL)",
         "Markets Insider"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/4/2025 9:14:54 PM</td>\n",
       "      <td>AAPL, JPM, GM: U.S. Stock Market Has Lost 11 T...</td>\n",
       "      <td>Markets Insider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/4/2025 5:49:29 PM</td>\n",
       "      <td>Earnings Could Drop by 28, Says Needham about ...</td>\n",
       "      <td>Markets Insider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          publish_date                                              title  \\\n",
       "0  4/4/2025 9:14:54 PM  AAPL, JPM, GM: U.S. Stock Market Has Lost 11 T...   \n",
       "1  4/4/2025 5:49:29 PM  Earnings Could Drop by 28, Says Needham about ...   \n",
       "\n",
       "            source  \n",
       "0  Markets Insider  \n",
       "1  Markets Insider  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the columns for the AAPL_market_vantage dataframe\n",
    "news_dict['AAPL_markets_insider'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from Markets Insider\n",
    "data_market = cl.extract_markets_insider(news_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "57eeaeb5-3642-48b7-b487-a33d6bc73cda",
       "rows": [
        [
         "0",
         "4/4/2025 9:14:54 PM",
         "AAPL, JPM, GM: U.S. Stock Market Has Lost 11 Trillion Since Trumps Inauguration",
         "Markets Insider"
        ],
        [
         "1",
         "4/4/2025 5:49:29 PM",
         "Earnings Could Drop by 28, Says Needham about Apple Stock (AAPL)",
         "Markets Insider"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4/4/2025 9:14:54 PM</td>\n",
       "      <td>AAPL, JPM, GM: U.S. Stock Market Has Lost 11 T...</td>\n",
       "      <td>Markets Insider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4/4/2025 5:49:29 PM</td>\n",
       "      <td>Earnings Could Drop by 28, Says Needham about ...</td>\n",
       "      <td>Markets Insider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date                                              title  \\\n",
       "0  4/4/2025 9:14:54 PM  AAPL, JPM, GM: U.S. Stock Market Has Lost 11 T...   \n",
       "1  4/4/2025 5:49:29 PM  Earnings Could Drop by 28, Says Needham about ...   \n",
       "\n",
       "            source  \n",
       "0  Markets Insider  \n",
       "1  Markets Insider  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL_markets_insider dataframe\n",
    "data_market['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the date format for the market data\n",
    "data_market = cl.standardize_datetime_format(data_market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "05aa01d9-79d0-4b92-afa4-619f341f6f14",
       "rows": [
        [
         "0",
         "2025-04-04 21:14:54",
         "AAPL, JPM, GM: U.S. Stock Market Has Lost 11 Trillion Since Trumps Inauguration",
         "Markets Insider"
        ],
        [
         "1",
         "2025-04-04 17:49:29",
         "Earnings Could Drop by 28, Says Needham about Apple Stock (AAPL)",
         "Markets Insider"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-04 21:14:54</td>\n",
       "      <td>AAPL, JPM, GM: U.S. Stock Market Has Lost 11 T...</td>\n",
       "      <td>Markets Insider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-04 17:49:29</td>\n",
       "      <td>Earnings Could Drop by 28, Says Needham about ...</td>\n",
       "      <td>Markets Insider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              title  \\\n",
       "0 2025-04-04 21:14:54  AAPL, JPM, GM: U.S. Stock Market Has Lost 11 T...   \n",
       "1 2025-04-04 17:49:29  Earnings Could Drop by 28, Says Needham about ...   \n",
       "\n",
       "            source  \n",
       "0  Markets Insider  \n",
       "1  Markets Insider  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL_markets_insider dataframe\n",
    "data_market['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL\n",
      "First date: 2019-12-11\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: AMZN\n",
      "First date: 2020-09-25\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: BAC\n",
      "First date: 2005-03-28\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: GME\n",
      "First date: 2011-06-28\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: GS\n",
      "First date: 2011-05-20\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: NVDA\n",
      "First date: 2014-01-06\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: TSLA\n",
      "First date: 2022-04-01\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Format date columnt \n",
    "dataframes_cleaned_markets_insider = cl.convert_date(data_market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b2e2a636-beae-4900-8ac1-ccbfa714068c",
       "rows": [
        [
         "0",
         "2025-04-04",
         "AAPL, JPM, GM: U.S. Stock Market Has Lost 11 Trillion Since Trumps Inauguration",
         "Markets Insider"
        ],
        [
         "1",
         "2025-04-04",
         "Earnings Could Drop by 28, Says Needham about Apple Stock (AAPL)",
         "Markets Insider"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>AAPL, JPM, GM: U.S. Stock Market Has Lost 11 T...</td>\n",
       "      <td>Markets Insider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>Earnings Could Drop by 28, Says Needham about ...</td>\n",
       "      <td>Markets Insider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title  \\\n",
       "0  2025-04-04  AAPL, JPM, GM: U.S. Stock Market Has Lost 11 T...   \n",
       "1  2025-04-04  Earnings Could Drop by 28, Says Needham about ...   \n",
       "\n",
       "            source  \n",
       "0  Markets Insider  \n",
       "1  Markets Insider  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL_markets_insider\n",
    "dataframes_cleaned_markets_insider['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved news_cleaned_dataframe_AAPL_markets_insider_news.csv\n",
      "Saved news_cleaned_dataframe_AMZN_markets_insider_news.csv\n",
      "Saved news_cleaned_dataframe_BAC_markets_insider_news.csv\n",
      "Saved news_cleaned_dataframe_GME_markets_insider_news.csv\n",
      "Saved news_cleaned_dataframe_GS_markets_insider_news.csv\n",
      "Saved news_cleaned_dataframe_NVDA_markets_insider_news.csv\n",
      "Saved news_cleaned_dataframe_TSLA_markets_insider_news.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the data frames\n",
    "cl.save_cleaned_dataframes(dataframes_cleaned_markets_insider, \"markets_insider_news\", data_folder_cleaned, prefix_word=\"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "publish_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cce24736-d3f6-43a5-9eb1-5c2c13a2c0f2",
       "rows": [
        [
         "0",
         "2022-04-06",
         "For 'Severance' star Adam Scott, there's no separation between work and home",
         "Google News"
        ],
        [
         "1",
         "2022-04-06",
         "Youre Still Being Tracked on the Internet, Just in a Different Way (Published 2022)",
         "Google News"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>For 'Severance' star Adam Scott, there's no se...</td>\n",
       "      <td>Google News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Youre Still Being Tracked on the Internet, Jus...</td>\n",
       "      <td>Google News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  publish_date                                              title       source\n",
       "0   2022-04-06  For 'Severance' star Adam Scott, there's no se...  Google News\n",
       "1   2022-04-06  Youre Still Being Tracked on the Internet, Jus...  Google News"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the columns for the AAPL_google_search dataframe\n",
    "news_dict['AAPL_google_search'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting data from Google Search\n",
    "data_google = cl.extract_google_search(news_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2b85d427-6232-4f70-a286-886a2453b0c7",
       "rows": [
        [
         "0",
         "2022-04-06",
         "For 'Severance' star Adam Scott, there's no separation between work and home",
         "Google News"
        ],
        [
         "1",
         "2022-04-06",
         "Youre Still Being Tracked on the Internet, Just in a Different Way (Published 2022)",
         "Google News"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>For 'Severance' star Adam Scott, there's no se...</td>\n",
       "      <td>Google News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Youre Still Being Tracked on the Internet, Jus...</td>\n",
       "      <td>Google News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title       source\n",
       "0  2022-04-06  For 'Severance' star Adam Scott, there's no se...  Google News\n",
       "1  2022-04-06  Youre Still Being Tracked on the Internet, Jus...  Google News"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL_google_search dataframe\n",
    "data_google['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AMZN\n",
      "First date: 2022-04-06\n",
      "Last date: 2025-04-05\n",
      "------------------------------\n",
      "Stock: AAPL\n",
      "First date: 2022-04-06\n",
      "Last date: 2025-04-05\n",
      "------------------------------\n",
      "Stock: BAC\n",
      "First date: 2022-04-06\n",
      "Last date: 2025-04-05\n",
      "------------------------------\n",
      "Stock: GME\n",
      "First date: 2022-04-08\n",
      "Last date: 2025-04-05\n",
      "------------------------------\n",
      "Stock: GS\n",
      "First date: 2022-04-06\n",
      "Last date: 2025-04-05\n",
      "------------------------------\n",
      "Stock: NVDA\n",
      "First date: 2022-04-06\n",
      "Last date: 2025-04-05\n",
      "------------------------------\n",
      "Stock: TSLA\n",
      "First date: 2022-04-06\n",
      "Last date: 2025-04-05\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Convert the date column to datetime format \n",
    "dataframes_cleaned_google_search = cl.convert_date(data_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3440912d-a6d4-4075-a9ec-6d22fbc09023",
       "rows": [
        [
         "0",
         "2022-04-06",
         "For 'Severance' star Adam Scott, there's no separation between work and home",
         "Google News"
        ],
        [
         "1",
         "2022-04-06",
         "Youre Still Being Tracked on the Internet, Just in a Different Way (Published 2022)",
         "Google News"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>For 'Severance' star Adam Scott, there's no se...</td>\n",
       "      <td>Google News</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Youre Still Being Tracked on the Internet, Jus...</td>\n",
       "      <td>Google News</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                              title       source\n",
       "0  2022-04-06  For 'Severance' star Adam Scott, there's no se...  Google News\n",
       "1  2022-04-06  Youre Still Being Tracked on the Internet, Jus...  Google News"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL_google_search\n",
    "dataframes_cleaned_google_search['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved news_cleaned_dataframe_AMZN_google_search_news.csv\n",
      "Saved news_cleaned_dataframe_AAPL_google_search_news.csv\n",
      "Saved news_cleaned_dataframe_BAC_google_search_news.csv\n",
      "Saved news_cleaned_dataframe_GME_google_search_news.csv\n",
      "Saved news_cleaned_dataframe_GS_google_search_news.csv\n",
      "Saved news_cleaned_dataframe_NVDA_google_search_news.csv\n",
      "Saved news_cleaned_dataframe_TSLA_google_search_news.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the data frames\n",
    "cl.save_cleaned_dataframes(dataframes_cleaned_google_search, \"google_search_news\", data_folder_cleaned, prefix_word=\"news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all the news dataframes into one dataframe\n",
    "news_combined = cl.concat_and_sort_dataframes_by_key([dataframes_cleaned_alpha_vantage, dataframes_cleaned_markets_insider, dataframes_cleaned_google_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbols = [\"TSLA\", \"AAPL\", \"AMZN\", \"NVDA\", \"GS\", \"BAC\", \"GME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 23134\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       1102\n",
      "title     22328\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    11500\n",
      "Google News        10959\n",
      "Alpha Vantage        675\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "30\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for TSLA\n",
    "ck.check(news_combined[stock_symbols[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 23132\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       1809\n",
      "title     22046\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    11500\n",
      "Google News        10960\n",
      "Alpha Vantage        672\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "106\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "107\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for AAPL\n",
    "ck.check(news_combined[stock_symbols[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 23149\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       1619\n",
      "title     21876\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    11500\n",
      "Google News        10959\n",
      "Alpha Vantage        690\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "42\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for AMZN\n",
    "ck.check(news_combined[stock_symbols[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 22266\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       2055\n",
      "title     20730\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    11195\n",
      "Google News        10389\n",
      "Alpha Vantage        682\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "89\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for NVDA\n",
    "ck.check(news_combined[stock_symbols[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 15877\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       2341\n",
      "title     14142\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Google News        10134\n",
      "Markets Insider     5060\n",
      "Alpha Vantage        683\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "171\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "180\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for GS\n",
    "ck.check(news_combined[stock_symbols[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 16682\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       2418\n",
      "title     15102\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Google News        10941\n",
      "Markets Insider     5035\n",
      "Alpha Vantage        706\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "90\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for BAC\n",
    "ck.check(news_combined[stock_symbols[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 6848\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date      1496\n",
      "title     6186\n",
      "source       3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    4193\n",
      "Google News        1963\n",
      "Alpha Vantage       692\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "11\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for GME\n",
    "ck.check(news_combined[stock_symbols[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remove duplicates from the news_combined dataframe in date and title columns \n",
    "# since the different sources may have the same news\n",
    "# and we want to keep only one of them.\n",
    "news_combined = cl.remove_duplicates_subset(news_combined, [\"date\", \"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 23100\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       1102\n",
      "title     22328\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    11480\n",
      "Google News        10950\n",
      "Alpha Vantage        670\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for TSLA again after removing duplicates\n",
    "ck.check(news_combined[stock_symbols[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 23025\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       1809\n",
      "title     22046\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    11396\n",
      "Google News        10959\n",
      "Alpha Vantage        670\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for AAPL again after removing duplicates\n",
    "ck.check(news_combined[stock_symbols[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 23097\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       1619\n",
      "title     21876\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    11462\n",
      "Google News        10954\n",
      "Alpha Vantage        681\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for AMZN again after removing duplicates\n",
    "ck.check(news_combined[stock_symbols[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 22140\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       2055\n",
      "title     20730\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    11099\n",
      "Google News        10368\n",
      "Alpha Vantage        673\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for NVDA again after removing duplicates\n",
    "ck.check(news_combined[stock_symbols[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 15697\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       2341\n",
      "title     14142\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Google News        10128\n",
      "Markets Insider     4899\n",
      "Alpha Vantage        670\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for GS again after removing duplicates\n",
    "ck.check(news_combined[stock_symbols[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 16582\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date       2418\n",
      "title     15102\n",
      "source        3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Google News        10938\n",
      "Markets Insider     4945\n",
      "Alpha Vantage        699\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for BAC again after removing duplicates\n",
    "ck.check(news_combined[stock_symbols[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 3 and rows: 6811\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "title             object\n",
      "source            object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date      1496\n",
      "title     6186\n",
      "source       3\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['source'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "source\n",
      "Markets Insider    4173\n",
      "Google News        1952\n",
      "Alpha Vantage       686\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "title     0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Lets check the new dataframe for GME again after removing duplicates\n",
    "ck.check(news_combined[stock_symbols[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined_cleaned_dataframe_AAPL_news.csv\n",
      "Saved combined_cleaned_dataframe_AMZN_news.csv\n",
      "Saved combined_cleaned_dataframe_BAC_news.csv\n",
      "Saved combined_cleaned_dataframe_GME_news.csv\n",
      "Saved combined_cleaned_dataframe_GS_news.csv\n",
      "Saved combined_cleaned_dataframe_NVDA_news.csv\n",
      "Saved combined_cleaned_dataframe_TSLA_news.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the combined dataframe\n",
    "cl.save_cleaned_dataframes(news_combined, \"news\", data_folder_cleaned, prefix_word=\"combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fake news data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bool_and_titles",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "952ebe26-c81c-43a4-bd80-220e66b1c166",
       "rows": [
        [
         "0",
         "0\tdonald trump sends out embarrassing new years eve message; this is disturbing"
        ],
        [
         "1",
         "0\tdrunk bragging trump staffer started russian collusion investigation"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bool_and_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0\\tdonald trump sends out embarrassing new yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0\\tdrunk bragging trump staffer started russia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     bool_and_titles\n",
       "0  0\\tdonald trump sends out embarrassing new yea...\n",
       "1  0\\tdrunk bragging trump staffer started russia..."
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look to the fake news data\n",
    "file_path = os.path.join(data_folder, 'training_data_fake_news.csv')\n",
    "df_fake_news_training = cl.load_csv_with_column_names(file_path)\n",
    "df_fake_news_training.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fake_news",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "9c81daf4-7ab0-4f46-8dac-2898a2c21289",
       "rows": [
        [
         "0",
         "0",
         "donald trump sends out embarrassing new years eve message; this is disturbing"
        ],
        [
         "1",
         "0",
         "drunk bragging trump staffer started russian collusion investigation"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_news</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump sends out embarrassing new years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fake_news                                              title\n",
       "0         0  donald trump sends out embarrassing new years...\n",
       "1         0  drunk bragging trump staffer started russian c..."
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's split the columns: one with the text and the other with the labels\n",
    "df_fake_news_training = cl.split_bool_and_titles_column(df_fake_news_training)\n",
    "df_fake_news_training.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 2 and rows: 34152\n",
      "\n",
      "Data types:\n",
      "fake_news    object\n",
      "title        object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "fake_news        2\n",
      "title        32206\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['fake_news'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "fake_news\n",
      "0    17572\n",
      "1    16580\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "fake_news    0\n",
      "title        0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "fake_news    0\n",
      "title        0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "1946\n"
     ]
    }
   ],
   "source": [
    "# Let;s have a look to the fake news data for training\n",
    "ck.check_fake(df_fake_news_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the fake news training data\n",
    "df_fake_news_training = cl.remove_duplicates(df_fake_news_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 2 and rows: 32206\n",
      "\n",
      "Data types:\n",
      "fake_news    object\n",
      "title        object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "fake_news        2\n",
      "title        32206\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['fake_news'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "fake_news\n",
      "1    16181\n",
      "0    16025\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "fake_news    0\n",
      "title        0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "fake_news    0\n",
      "title        0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Let's check the fake news training data after removing duplicates\n",
    "ck.check_fake(df_fake_news_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame: training_data_cleaned_fake_news.csv\n"
     ]
    }
   ],
   "source": [
    "# Let's save the fake news data into a cleaned csv file\n",
    "cl.save_dataframe_to_csv(df_fake_news_training, data_folder_cleaned, 'training_data_cleaned_fake_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "bool_and_titles",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5ba780fa-f3fa-487c-a136-6caf75ac8984",
       "rows": [
        [
         "0",
         "2\tcopycat muslim terrorist arrested with assault weapons"
        ],
        [
         "1",
         "2\twow! chicago protester caught on camera admits violent activity was pre-planned: its not gonna be peaceful"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bool_and_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2\\tcopycat muslim terrorist arrested with assa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2\\twow! chicago protester caught on camera adm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     bool_and_titles\n",
       "0  2\\tcopycat muslim terrorist arrested with assa...\n",
       "1  2\\twow! chicago protester caught on camera adm..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look to the fake news data for prediction\n",
    "file_path = os.path.join(data_folder, 'testing_data_fake_news.csv')\n",
    "df_fake_news_testing = cl.load_csv_with_column_names(file_path)\n",
    "df_fake_news_testing.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fake_news",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e42cdcfa-e928-410f-8f55-b4c5923e55bf",
       "rows": [
        [
         "0",
         "2",
         "copycat muslim terrorist arrested with assault weapons"
        ],
        [
         "1",
         "2",
         "wow! chicago protester caught on camera admits violent activity was pre-planned: its not gonna be peaceful"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fake_news</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>copycat muslim terrorist arrested with assault...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wow! chicago protester caught on camera admits...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fake_news                                              title\n",
       "0         2  copycat muslim terrorist arrested with assault...\n",
       "1         2  wow! chicago protester caught on camera admits..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's split the columns: one with the text and the other with the labels\n",
    "df_fake_news_testing = cl.split_bool_and_titles_column(df_fake_news_testing)\n",
    "df_fake_news_testing.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 2 and rows: 9984\n",
      "\n",
      "Data types:\n",
      "fake_news    object\n",
      "title        object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "fake_news       2\n",
      "title        9208\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['fake_news'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "fake_news\n",
      "2     9982\n",
      "0       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "fake_news    0\n",
      "title        0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "fake_news    0\n",
      "title        0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "775\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look to the fake news data for prediction\n",
    "ck.check_fake(df_fake_news_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates from the fake news training data\n",
    "df_fake_news_testing = cl.remove_duplicates(df_fake_news_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 2 and rows: 9209\n",
      "\n",
      "Data types:\n",
      "fake_news    object\n",
      "title        object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "fake_news       2\n",
      "title        9208\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index(['fake_news'], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "fake_news\n",
      "2     9207\n",
      "0       2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Count of null values:\n",
      "fake_news    0\n",
      "title        0\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "fake_news    0\n",
      "title        0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Let's have a look to the fake news data for prediction after removing duplicates\n",
    "ck.check_fake(df_fake_news_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved DataFrame: testing_data_cleaned_fake_news.csv\n"
     ]
    }
   ],
   "source": [
    "# Let's save the fake news data into a cleaned csv file\n",
    "cl.save_dataframe_to_csv(df_fake_news_testing, data_folder_cleaned, 'testing_data_cleaned_fake_news.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha Vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "1. open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "2. high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "3. low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "4. close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "5. volume",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8479bb81-6715-42e8-8b13-128f4034b9bb",
       "rows": [
        [
         "0",
         "2025-04-04",
         "193.89",
         "199.88",
         "187.34",
         "188.38",
         "125910913"
        ],
        [
         "1",
         "2025-04-03",
         "205.54",
         "207.49",
         "201.25",
         "203.19",
         "103419006"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>193.89</td>\n",
       "      <td>199.88</td>\n",
       "      <td>187.34</td>\n",
       "      <td>188.38</td>\n",
       "      <td>125910913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>205.54</td>\n",
       "      <td>207.49</td>\n",
       "      <td>201.25</td>\n",
       "      <td>203.19</td>\n",
       "      <td>103419006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  1. open  2. high  3. low  4. close  5. volume\n",
       "0  2025-04-04   193.89   199.88  187.34    188.38  125910913\n",
       "1  2025-04-03   205.54   207.49  201.25    203.19  103419006"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the columns for the AAPL_alpha_vantage dataframe\n",
    "stocks_dict['AAPL_alpha_vantage'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean the columns names\n",
    "for key in stocks_dict.keys():\n",
    "    stocks_dict[key] = cl.clean_column_names(stocks_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets rename the columns to the ticker name\n",
    "stocks_dict = cl.rename_keys_to_ticker(stocks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": " open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " volume",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cc00b785-1ace-4cc1-8f80-80708e153852",
       "rows": [
        [
         "0",
         "2025-04-04",
         "193.89",
         "199.88",
         "187.34",
         "188.38",
         "125910913"
        ],
        [
         "1",
         "2025-04-03",
         "205.54",
         "207.49",
         "201.25",
         "203.19",
         "103419006"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>193.89</td>\n",
       "      <td>199.88</td>\n",
       "      <td>187.34</td>\n",
       "      <td>188.38</td>\n",
       "      <td>125910913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>205.54</td>\n",
       "      <td>207.49</td>\n",
       "      <td>201.25</td>\n",
       "      <td>203.19</td>\n",
       "      <td>103419006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open    high     low   close     volume\n",
       "0  2025-04-04  193.89  199.88  187.34  188.38  125910913\n",
       "1  2025-04-03  205.54  207.49  201.25  203.19  103419006"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the columns for the AAP dataframe\n",
    "stocks_dict['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL\n",
      "First date: 1999-11-01\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: AMZN\n",
      "First date: 1999-11-01\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: BAC\n",
      "First date: 1999-11-01\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: GME\n",
      "First date: 2002-02-13\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: GS\n",
      "First date: 1999-11-01\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: NVDA\n",
      "First date: 1999-11-01\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n",
      "Stock: TSLA\n",
      "First date: 2010-06-29\n",
      "Last date: 2025-04-04\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set date in correct format \n",
    "dataframes_cleaned_stock = cl.convert_date(stocks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": " open",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " high",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " low",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " close",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": " volume",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3581f884-0afa-44fc-a29a-2c7ce23c8cf3",
       "rows": [
        [
         "0",
         "2025-04-04",
         "193.89",
         "199.88",
         "187.34",
         "188.38",
         "125910913"
        ],
        [
         "1",
         "2025-04-03",
         "205.54",
         "207.49",
         "201.25",
         "203.19",
         "103419006"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-04-04</td>\n",
       "      <td>193.89</td>\n",
       "      <td>199.88</td>\n",
       "      <td>187.34</td>\n",
       "      <td>188.38</td>\n",
       "      <td>125910913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-04-03</td>\n",
       "      <td>205.54</td>\n",
       "      <td>207.49</td>\n",
       "      <td>201.25</td>\n",
       "      <td>203.19</td>\n",
       "      <td>103419006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open    high     low   close     volume\n",
       "0  2025-04-04  193.89  199.88  187.34  188.38  125910913\n",
       "1  2025-04-03  205.54  207.49  201.25  203.19  103419006"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets check the columns for the AAPL\n",
    "dataframes_cleaned_stock['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stocks_cleaned_dataframe_AAPL_alpha_vantage.csv\n",
      "Saved stocks_cleaned_dataframe_AMZN_alpha_vantage.csv\n",
      "Saved stocks_cleaned_dataframe_BAC_alpha_vantage.csv\n",
      "Saved stocks_cleaned_dataframe_GME_alpha_vantage.csv\n",
      "Saved stocks_cleaned_dataframe_GS_alpha_vantage.csv\n",
      "Saved stocks_cleaned_dataframe_NVDA_alpha_vantage.csv\n",
      "Saved stocks_cleaned_dataframe_TSLA_alpha_vantage.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the data frames\n",
    "cl.save_cleaned_dataframes(dataframes_cleaned_stock, \"alpha_vantage\", data_folder_cleaned, prefix_word=\"stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yahoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Close",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "High",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Low",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Open",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Volume",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4bc4ef30-48e2-4ac4-80ef-a96db3a99922",
       "rows": [
        [
         "0",
         null,
         "AAPL",
         "AAPL",
         "AAPL",
         "AAPL",
         "AAPL"
        ],
        [
         "1",
         "2022-05-09",
         "149.85523986816406",
         "153.5705818622736",
         "149.29351226682695",
         "152.68362217522588",
         "131577900"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>149.85523986816406</td>\n",
       "      <td>153.5705818622736</td>\n",
       "      <td>149.29351226682695</td>\n",
       "      <td>152.68362217522588</td>\n",
       "      <td>131577900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date               Close               High                 Low  \\\n",
       "0         NaN                AAPL               AAPL                AAPL   \n",
       "1  2022-05-09  149.85523986816406  153.5705818622736  149.29351226682695   \n",
       "\n",
       "                 Open     Volume  \n",
       "0                AAPL       AAPL  \n",
       "1  152.68362217522588  131577900  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the columns for the stock_AAPL_yahoo dataframe\n",
    "stocks_dict_yahoo['stock_AAPL_yahoo'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean the columns\n",
    "for key in stocks_dict_yahoo.keys():\n",
    "    stocks_dict_yahoo[key] = cl.remove_first_row(stocks_dict_yahoo[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets clean the columns names\n",
    "for key in stocks_dict_yahoo.keys():\n",
    "    stocks_dict_yahoo[key] = cl.snake(stocks_dict_yahoo[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "close",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "high",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "low",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "volume",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c17baf2c-2a3e-4aa2-aad7-6034d303d85e",
       "rows": [
        [
         "0",
         "2022-05-09",
         "149.85523986816406",
         "153.5705818622736",
         "149.29351226682695",
         "152.68362217522588",
         "131577900"
        ],
        [
         "1",
         "2022-05-10",
         "152.26968383789062",
         "154.46736088090017",
         "150.71259117184084",
         "153.26504901265346",
         "115366700"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>149.85523986816406</td>\n",
       "      <td>153.5705818622736</td>\n",
       "      <td>149.29351226682695</td>\n",
       "      <td>152.68362217522588</td>\n",
       "      <td>131577900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>152.26968383789062</td>\n",
       "      <td>154.46736088090017</td>\n",
       "      <td>150.71259117184084</td>\n",
       "      <td>153.26504901265346</td>\n",
       "      <td>115366700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date               close                high                 low  \\\n",
       "0  2022-05-09  149.85523986816406   153.5705818622736  149.29351226682695   \n",
       "1  2022-05-10  152.26968383789062  154.46736088090017  150.71259117184084   \n",
       "\n",
       "                 open     volume  \n",
       "0  152.68362217522588  131577900  \n",
       "1  153.26504901265346  115366700  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_dict_yahoo['stock_AAPL_yahoo'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets rename the columns to the ticker name\n",
    "stocks_dict_yahoo = cl.rename_keys_to_ticker(stocks_dict_yahoo, pos =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock: AAPL\n",
      "First date: 2022-05-09\n",
      "Last date: 2025-05-07\n",
      "------------------------------\n",
      "Stock: AMZN\n",
      "First date: 2022-05-09\n",
      "Last date: 2025-05-07\n",
      "------------------------------\n",
      "Stock: BAC\n",
      "First date: 2022-05-09\n",
      "Last date: 2025-05-07\n",
      "------------------------------\n",
      "Stock: GME\n",
      "First date: 2022-05-09\n",
      "Last date: 2025-05-07\n",
      "------------------------------\n",
      "Stock: GS\n",
      "First date: 2022-05-09\n",
      "Last date: 2025-05-07\n",
      "------------------------------\n",
      "Stock: NVDA\n",
      "First date: 2022-05-09\n",
      "Last date: 2025-05-07\n",
      "------------------------------\n",
      "Stock: TSLA\n",
      "First date: 2022-05-09\n",
      "Last date: 2025-05-07\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Set date in correct format \n",
    "dataframes_cleaned_stock_yahoo = cl.convert_date(stocks_dict_yahoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "close",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "high",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "low",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "volume",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cb96b980-fb07-4e93-8472-6d893cc160ee",
       "rows": [
        [
         "0",
         "2022-05-09",
         "149.85523986816406",
         "153.5705818622736",
         "149.29351226682695",
         "152.68362217522588",
         "131577900"
        ],
        [
         "1",
         "2022-05-10",
         "152.26968383789062",
         "154.46736088090017",
         "150.71259117184084",
         "153.26504901265346",
         "115366700"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>149.85523986816406</td>\n",
       "      <td>153.5705818622736</td>\n",
       "      <td>149.29351226682695</td>\n",
       "      <td>152.68362217522588</td>\n",
       "      <td>131577900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>152.26968383789062</td>\n",
       "      <td>154.46736088090017</td>\n",
       "      <td>150.71259117184084</td>\n",
       "      <td>153.26504901265346</td>\n",
       "      <td>115366700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date               close                high                 low  \\\n",
       "0  2022-05-09  149.85523986816406   153.5705818622736  149.29351226682695   \n",
       "1  2022-05-10  152.26968383789062  154.46736088090017  150.71259117184084   \n",
       "\n",
       "                 open     volume  \n",
       "0  152.68362217522588  131577900  \n",
       "1  153.26504901265346  115366700  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_cleaned_stock_yahoo['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stocks_cleaned_dataframe_AAPL_yahoo.csv\n",
      "Saved stocks_cleaned_dataframe_AMZN_yahoo.csv\n",
      "Saved stocks_cleaned_dataframe_BAC_yahoo.csv\n",
      "Saved stocks_cleaned_dataframe_GME_yahoo.csv\n",
      "Saved stocks_cleaned_dataframe_GS_yahoo.csv\n",
      "Saved stocks_cleaned_dataframe_NVDA_yahoo.csv\n",
      "Saved stocks_cleaned_dataframe_TSLA_yahoo.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the data frames\n",
    "cl.save_cleaned_dataframes(dataframes_cleaned_stock_yahoo, \"yahoo\", data_folder_cleaned, prefix_word=\"stocks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging news and stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging same days new per stock\n",
    "processed_news = cl.process_news_data(news_combined)\n",
    "\n",
    "# Merging the stocks dataframes with the news dataframes\n",
    "merged_dict =  cl.merge_stock_and_news(dataframes_cleaned_stock_yahoo, processed_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "close",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "high",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "low",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "volume",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "06516122-866b-4714-8e93-a17adad99b51",
       "rows": [
        [
         "0",
         "2022-05-09 00:00:00",
         "149.85523986816406",
         "153.5705818622736",
         "149.29351226682695",
         "152.68362217522588",
         "131577900",
         "4 BlueChip Stocks to Buy for May 2022 Where to Invest During Inflation? 3 Top Investments to Consider. Be Ready: New AirPods Pro, Fresh Colors For AirPods Max Could Be Coming This Fall Morning Brief: Top Financial Stories Dominating on Monday, May 9 3 Reasons to Buy the Dip In Apple Stock (and When) WeChat Gives Cues On Why Elon Musk's Ambitious Twitter Revenue Plan Is 'Achievable:' Analyst Georgia nuclear plant's cost now forecast to top 30 billion New Mix: Regina Spektor, Stella Donnelly, Tomberlin, More : All Songs Considered SP 500 ends below 4,000 for 1st time since March 2021; growth shares lead decline Inventor of BrainScan Helmet Takes Ketamine to Test His Technology Sold for 195 million, Andy Warhols Shot Sage Blue Marilyn sets new auction record BMW Shipping New Cars Temporarily Without Apple CarPlay Opinion: County must rethink release of dangerous pandemicera inmates UF seems to endorse new state antiCRT law Paddle, the company that wants to take on Apple in IAP, raises 200M at a 1.4B valuation to supercharge SaaS payments Apple targeted for Safari lacking WebXR support despite companys ARVR ambitions"
        ],
        [
         "1",
         "2022-05-10 00:00:00",
         "152.26968383789062",
         "154.46736088090017",
         "150.71259117184084",
         "153.26504901265346",
         "115366700",
         "Twitter Stock Has Risks After Deal With Elon Musk Cathie Wood May Be Betting on General Motors But TSLA Stock Is Still the Best 6 Stocks to Buy to Counter High Inflation That Will Do Well This Year Apple Stock Is Compelling for Serious Investors Aramco replaces Apple as world's largest company by market capitalization Noted Apple, Tesla Analyst Says Market In A Bubble: 'Wish I Had Better News' Sorry GME Stock Fans, Theres Still Little to Like About GameStop Why Its Time to Buy Digital World Acquisition Stock Again Amazon Is Down Almost 40, Time to Consider Buying AMZN Stock ICYMI: Me and My Uncle, Remembering the Flood of 1972 as an Emerald Apple is discontinuing its last iPod model The music lives on Apple to pull the plug on iPod after 20 years How period tracking apps and data privacy fit into a postRoe v. Wade climate The iPod touch and 'iPod' brand are officially dead Apple announced the iPod is dead Farewell to the iPod (Published 2022) 'Shouldn't Remembering Them Mean Knowing More About Them?' An Interview With Don Milne, Founder of Stories Behind the Stars Is European Union Apple Pay Investigation Bad News for Apple Stock? Unconstitutional Jim Crow Juries Locked Them Up. Theyre Still In Prison."
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>149.85523986816406</td>\n",
       "      <td>153.5705818622736</td>\n",
       "      <td>149.29351226682695</td>\n",
       "      <td>152.68362217522588</td>\n",
       "      <td>131577900</td>\n",
       "      <td>4 BlueChip Stocks to Buy for May 2022 Where to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>152.26968383789062</td>\n",
       "      <td>154.46736088090017</td>\n",
       "      <td>150.71259117184084</td>\n",
       "      <td>153.26504901265346</td>\n",
       "      <td>115366700</td>\n",
       "      <td>Twitter Stock Has Risks After Deal With Elon M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date               close                high                 low  \\\n",
       "0 2022-05-09  149.85523986816406   153.5705818622736  149.29351226682695   \n",
       "1 2022-05-10  152.26968383789062  154.46736088090017  150.71259117184084   \n",
       "\n",
       "                 open     volume  \\\n",
       "0  152.68362217522588  131577900   \n",
       "1  153.26504901265346  115366700   \n",
       "\n",
       "                                               title  \n",
       "0  4 BlueChip Stocks to Buy for May 2022 Where to...  \n",
       "1  Twitter Stock Has Risks After Deal With Elon M...  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict['AAPL'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 7 and rows: 752\n",
      "\n",
      "Data types:\n",
      "date      datetime64[ns]\n",
      "close             object\n",
      "high              object\n",
      "low               object\n",
      "open              object\n",
      "volume            object\n",
      "title             object\n",
      "dtype: object\n",
      "\n",
      "Unique values count:\n",
      "date      752\n",
      "close     744\n",
      "high      752\n",
      "low       752\n",
      "open      752\n",
      "volume    752\n",
      "title     730\n",
      "dtype: int64\n",
      "\n",
      "These columns appear to be categorical (less than 20 unique values):\n",
      "Index([], dtype='object')\n",
      "\n",
      "Unique value count for categorical columns:\n",
      "\n",
      "Count of null values:\n",
      "date       0\n",
      "close      0\n",
      "high       0\n",
      "low        0\n",
      "open       0\n",
      "volume     0\n",
      "title     22\n",
      "dtype: int64\n",
      "\n",
      "Count of missing() values:\n",
      "date      0\n",
      "close     0\n",
      "high      0\n",
      "low       0\n",
      "open      0\n",
      "volume    0\n",
      "title     0\n",
      "dtype: int64\n",
      "\n",
      "Count of duplicated values:\n",
      "0\n",
      "\n",
      "Count of duplicated values in subset:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ck.check(merged_dict['AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "date",
         "rawType": "datetime64[ns]",
         "type": "datetime"
        },
        {
         "name": "close",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "high",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "low",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "open",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "volume",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b3919d6a-0c59-4b81-82aa-6b27277c6460",
       "rows": [
        [
         "730",
         "2025-04-07 00:00:00",
         "181.4600067138672",
         "194.14999389648438",
         "174.6199951171875",
         "177.1999969482422",
         "160466300",
         null
        ],
        [
         "731",
         "2025-04-08 00:00:00",
         "172.4199981689453",
         "190.33999633789062",
         "169.2100067138672",
         "186.6999969482422",
         "120859500",
         null
        ],
        [
         "732",
         "2025-04-09 00:00:00",
         "198.85000610351562",
         "200.61000061035156",
         "171.88999938964844",
         "171.9499969482422",
         "184395900",
         null
        ],
        [
         "733",
         "2025-04-10 00:00:00",
         "190.4199981689453",
         "194.77999877929688",
         "183.0",
         "189.07000732421875",
         "121880000",
         null
        ],
        [
         "734",
         "2025-04-11 00:00:00",
         "198.14999389648438",
         "199.5399932861328",
         "186.05999755859375",
         "186.10000610351562",
         "87435900",
         null
        ],
        [
         "735",
         "2025-04-14 00:00:00",
         "202.52000427246094",
         "212.94000244140625",
         "201.16000366210938",
         "211.44000244140625",
         "101352900",
         null
        ],
        [
         "736",
         "2025-04-15 00:00:00",
         "202.13999938964844",
         "203.50999450683594",
         "199.8000030517578",
         "201.86000061035156",
         "51343900",
         null
        ],
        [
         "737",
         "2025-04-16 00:00:00",
         "194.27000427246094",
         "200.6999969482422",
         "192.3699951171875",
         "198.36000061035156",
         "59732400",
         null
        ],
        [
         "738",
         "2025-04-17 00:00:00",
         "196.97999572753906",
         "198.8300018310547",
         "194.4199981689453",
         "197.1999969482422",
         "51334300",
         null
        ],
        [
         "739",
         "2025-04-21 00:00:00",
         "193.16000366210938",
         "193.8000030517578",
         "189.80999755859375",
         "193.27000427246094",
         "46742500",
         null
        ],
        [
         "740",
         "2025-04-22 00:00:00",
         "199.74000549316406",
         "201.58999633789062",
         "195.97000122070312",
         "196.1199951171875",
         "52976400",
         null
        ],
        [
         "741",
         "2025-04-23 00:00:00",
         "204.60000610351562",
         "208.0",
         "202.8000030517578",
         "206.0",
         "52929200",
         null
        ],
        [
         "742",
         "2025-04-24 00:00:00",
         "208.3699951171875",
         "208.8300018310547",
         "202.94000244140625",
         "204.88999938964844",
         "47311000",
         null
        ],
        [
         "743",
         "2025-04-25 00:00:00",
         "209.27999877929688",
         "209.75",
         "206.1999969482422",
         "206.3699951171875",
         "38222300",
         null
        ],
        [
         "744",
         "2025-04-28 00:00:00",
         "210.13999938964844",
         "211.5",
         "207.4600067138672",
         "210.0",
         "38743100",
         null
        ],
        [
         "745",
         "2025-04-29 00:00:00",
         "211.2100067138672",
         "212.24000549316406",
         "208.3699951171875",
         "208.69000244140625",
         "36827600",
         null
        ],
        [
         "746",
         "2025-04-30 00:00:00",
         "212.5",
         "213.5800018310547",
         "206.6699981689453",
         "209.3000030517578",
         "52286500",
         null
        ],
        [
         "747",
         "2025-05-01 00:00:00",
         "213.32000732421875",
         "214.55999755859375",
         "208.89999389648438",
         "209.0800018310547",
         "57365700",
         null
        ],
        [
         "748",
         "2025-05-02 00:00:00",
         "205.35000610351562",
         "206.99000549316406",
         "202.16000366210938",
         "206.08999633789062",
         "101010600",
         null
        ],
        [
         "749",
         "2025-05-05 00:00:00",
         "198.88999938964844",
         "204.10000610351562",
         "198.2100067138672",
         "203.10000610351562",
         "69018500",
         null
        ],
        [
         "750",
         "2025-05-06 00:00:00",
         "198.50999450683594",
         "200.64999389648438",
         "197.02000427246094",
         "198.2100067138672",
         "51216500",
         null
        ],
        [
         "751",
         "2025-05-07 00:00:00",
         "196.25",
         "199.44000244140625",
         "193.25",
         "199.1699981689453",
         "68616900",
         null
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 22
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>181.4600067138672</td>\n",
       "      <td>194.14999389648438</td>\n",
       "      <td>174.6199951171875</td>\n",
       "      <td>177.1999969482422</td>\n",
       "      <td>160466300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>2025-04-08</td>\n",
       "      <td>172.4199981689453</td>\n",
       "      <td>190.33999633789062</td>\n",
       "      <td>169.2100067138672</td>\n",
       "      <td>186.6999969482422</td>\n",
       "      <td>120859500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>2025-04-09</td>\n",
       "      <td>198.85000610351562</td>\n",
       "      <td>200.61000061035156</td>\n",
       "      <td>171.88999938964844</td>\n",
       "      <td>171.9499969482422</td>\n",
       "      <td>184395900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2025-04-10</td>\n",
       "      <td>190.4199981689453</td>\n",
       "      <td>194.77999877929688</td>\n",
       "      <td>183.0</td>\n",
       "      <td>189.07000732421875</td>\n",
       "      <td>121880000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>2025-04-11</td>\n",
       "      <td>198.14999389648438</td>\n",
       "      <td>199.5399932861328</td>\n",
       "      <td>186.05999755859375</td>\n",
       "      <td>186.10000610351562</td>\n",
       "      <td>87435900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>2025-04-14</td>\n",
       "      <td>202.52000427246094</td>\n",
       "      <td>212.94000244140625</td>\n",
       "      <td>201.16000366210938</td>\n",
       "      <td>211.44000244140625</td>\n",
       "      <td>101352900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>202.13999938964844</td>\n",
       "      <td>203.50999450683594</td>\n",
       "      <td>199.8000030517578</td>\n",
       "      <td>201.86000061035156</td>\n",
       "      <td>51343900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>2025-04-16</td>\n",
       "      <td>194.27000427246094</td>\n",
       "      <td>200.6999969482422</td>\n",
       "      <td>192.3699951171875</td>\n",
       "      <td>198.36000061035156</td>\n",
       "      <td>59732400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2025-04-17</td>\n",
       "      <td>196.97999572753906</td>\n",
       "      <td>198.8300018310547</td>\n",
       "      <td>194.4199981689453</td>\n",
       "      <td>197.1999969482422</td>\n",
       "      <td>51334300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>2025-04-21</td>\n",
       "      <td>193.16000366210938</td>\n",
       "      <td>193.8000030517578</td>\n",
       "      <td>189.80999755859375</td>\n",
       "      <td>193.27000427246094</td>\n",
       "      <td>46742500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>2025-04-22</td>\n",
       "      <td>199.74000549316406</td>\n",
       "      <td>201.58999633789062</td>\n",
       "      <td>195.97000122070312</td>\n",
       "      <td>196.1199951171875</td>\n",
       "      <td>52976400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>2025-04-23</td>\n",
       "      <td>204.60000610351562</td>\n",
       "      <td>208.0</td>\n",
       "      <td>202.8000030517578</td>\n",
       "      <td>206.0</td>\n",
       "      <td>52929200</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>2025-04-24</td>\n",
       "      <td>208.3699951171875</td>\n",
       "      <td>208.8300018310547</td>\n",
       "      <td>202.94000244140625</td>\n",
       "      <td>204.88999938964844</td>\n",
       "      <td>47311000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>2025-04-25</td>\n",
       "      <td>209.27999877929688</td>\n",
       "      <td>209.75</td>\n",
       "      <td>206.1999969482422</td>\n",
       "      <td>206.3699951171875</td>\n",
       "      <td>38222300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>2025-04-28</td>\n",
       "      <td>210.13999938964844</td>\n",
       "      <td>211.5</td>\n",
       "      <td>207.4600067138672</td>\n",
       "      <td>210.0</td>\n",
       "      <td>38743100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>2025-04-29</td>\n",
       "      <td>211.2100067138672</td>\n",
       "      <td>212.24000549316406</td>\n",
       "      <td>208.3699951171875</td>\n",
       "      <td>208.69000244140625</td>\n",
       "      <td>36827600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>2025-04-30</td>\n",
       "      <td>212.5</td>\n",
       "      <td>213.5800018310547</td>\n",
       "      <td>206.6699981689453</td>\n",
       "      <td>209.3000030517578</td>\n",
       "      <td>52286500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>213.32000732421875</td>\n",
       "      <td>214.55999755859375</td>\n",
       "      <td>208.89999389648438</td>\n",
       "      <td>209.0800018310547</td>\n",
       "      <td>57365700</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>2025-05-02</td>\n",
       "      <td>205.35000610351562</td>\n",
       "      <td>206.99000549316406</td>\n",
       "      <td>202.16000366210938</td>\n",
       "      <td>206.08999633789062</td>\n",
       "      <td>101010600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>2025-05-05</td>\n",
       "      <td>198.88999938964844</td>\n",
       "      <td>204.10000610351562</td>\n",
       "      <td>198.2100067138672</td>\n",
       "      <td>203.10000610351562</td>\n",
       "      <td>69018500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>198.50999450683594</td>\n",
       "      <td>200.64999389648438</td>\n",
       "      <td>197.02000427246094</td>\n",
       "      <td>198.2100067138672</td>\n",
       "      <td>51216500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>2025-05-07</td>\n",
       "      <td>196.25</td>\n",
       "      <td>199.44000244140625</td>\n",
       "      <td>193.25</td>\n",
       "      <td>199.1699981689453</td>\n",
       "      <td>68616900</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date               close                high                 low  \\\n",
       "730 2025-04-07   181.4600067138672  194.14999389648438   174.6199951171875   \n",
       "731 2025-04-08   172.4199981689453  190.33999633789062   169.2100067138672   \n",
       "732 2025-04-09  198.85000610351562  200.61000061035156  171.88999938964844   \n",
       "733 2025-04-10   190.4199981689453  194.77999877929688               183.0   \n",
       "734 2025-04-11  198.14999389648438   199.5399932861328  186.05999755859375   \n",
       "735 2025-04-14  202.52000427246094  212.94000244140625  201.16000366210938   \n",
       "736 2025-04-15  202.13999938964844  203.50999450683594   199.8000030517578   \n",
       "737 2025-04-16  194.27000427246094   200.6999969482422   192.3699951171875   \n",
       "738 2025-04-17  196.97999572753906   198.8300018310547   194.4199981689453   \n",
       "739 2025-04-21  193.16000366210938   193.8000030517578  189.80999755859375   \n",
       "740 2025-04-22  199.74000549316406  201.58999633789062  195.97000122070312   \n",
       "741 2025-04-23  204.60000610351562               208.0   202.8000030517578   \n",
       "742 2025-04-24   208.3699951171875   208.8300018310547  202.94000244140625   \n",
       "743 2025-04-25  209.27999877929688              209.75   206.1999969482422   \n",
       "744 2025-04-28  210.13999938964844               211.5   207.4600067138672   \n",
       "745 2025-04-29   211.2100067138672  212.24000549316406   208.3699951171875   \n",
       "746 2025-04-30               212.5   213.5800018310547   206.6699981689453   \n",
       "747 2025-05-01  213.32000732421875  214.55999755859375  208.89999389648438   \n",
       "748 2025-05-02  205.35000610351562  206.99000549316406  202.16000366210938   \n",
       "749 2025-05-05  198.88999938964844  204.10000610351562   198.2100067138672   \n",
       "750 2025-05-06  198.50999450683594  200.64999389648438  197.02000427246094   \n",
       "751 2025-05-07              196.25  199.44000244140625              193.25   \n",
       "\n",
       "                   open     volume title  \n",
       "730   177.1999969482422  160466300   NaN  \n",
       "731   186.6999969482422  120859500   NaN  \n",
       "732   171.9499969482422  184395900   NaN  \n",
       "733  189.07000732421875  121880000   NaN  \n",
       "734  186.10000610351562   87435900   NaN  \n",
       "735  211.44000244140625  101352900   NaN  \n",
       "736  201.86000061035156   51343900   NaN  \n",
       "737  198.36000061035156   59732400   NaN  \n",
       "738   197.1999969482422   51334300   NaN  \n",
       "739  193.27000427246094   46742500   NaN  \n",
       "740   196.1199951171875   52976400   NaN  \n",
       "741               206.0   52929200   NaN  \n",
       "742  204.88999938964844   47311000   NaN  \n",
       "743   206.3699951171875   38222300   NaN  \n",
       "744               210.0   38743100   NaN  \n",
       "745  208.69000244140625   36827600   NaN  \n",
       "746   209.3000030517578   52286500   NaN  \n",
       "747   209.0800018310547   57365700   NaN  \n",
       "748  206.08999633789062  101010600   NaN  \n",
       "749  203.10000610351562   69018500   NaN  \n",
       "750   198.2100067138672   51216500   NaN  \n",
       "751   199.1699981689453   68616900   NaN  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dict['AAPL'][merged_dict['AAPL']['title'].isna()].head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The last dates are not include in the news dataframes so result in NaN values, for the analysis we can drop them\n",
    "for key in merged_dict.keys():\n",
    "    merged_dict[key] = merged_dict[key].dropna(subset=['title'])\n",
    "    merged_dict[key] = merged_dict[key].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved stocks_news_cleaned_dataframe_AAPL_merged.csv\n",
      "Saved stocks_news_cleaned_dataframe_AMZN_merged.csv\n",
      "Saved stocks_news_cleaned_dataframe_BAC_merged.csv\n",
      "Saved stocks_news_cleaned_dataframe_GME_merged.csv\n",
      "Saved stocks_news_cleaned_dataframe_GS_merged.csv\n",
      "Saved stocks_news_cleaned_dataframe_NVDA_merged.csv\n",
      "Saved stocks_news_cleaned_dataframe_TSLA_merged.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving the data frames\n",
    "cl.save_cleaned_dataframes(merged_dict, \"merged\", data_folder_cleaned, prefix_word=\"stocks_news\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
